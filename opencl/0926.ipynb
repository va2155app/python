{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import, print_function\n",
    "import numpy as np\n",
    "import pyopencl as cl\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose platform:\n",
      "[0] <pyopencl.Platform 'NVIDIA CUDA' at 0x22b358cf170>\n",
      "[1] <pyopencl.Platform 'Intel(R) OpenCL HD Graphics' at 0x22b35a57bf0>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choice [0]: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set the environment variable PYOPENCL_CTX='1' to avoid being asked again.\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "a_np = np.random.rand(50000).astype(np.float32)\n",
    "b_np = np.random.rand(50000).astype(np.float32)\n",
    "\n",
    "ctx = cl.create_some_context(1)\n",
    "queue = cl.CommandQueue(ctx)\n",
    "\n",
    "mf = cl.mem_flags\n",
    "a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)\n",
    "b_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b_np)\n",
    "\n",
    "prg = cl.Program(ctx, \"\"\"\n",
    "__kernel void sum(\n",
    "    __global const float *a_g, __global const float *b_g, __global float *res_g)\n",
    "{\n",
    "  int gid = get_global_id(0);\n",
    "  res_g[gid] = a_g[gid] + b_g[gid];\n",
    "}\n",
    "\"\"\").build()\n",
    "\n",
    "res_g = cl.Buffer(ctx, mf.WRITE_ONLY, a_np.nbytes)\n",
    "prg.sum(queue, a_np.shape, None, a_g, b_g, res_g)\n",
    "\n",
    "res_np = np.empty_like(a_np)\n",
    "cl.enqueue_copy(queue, res_np, res_g)\n",
    "\n",
    "# Check on CPU with Numpy:\n",
    "print(res_np - (a_np + b_np))\n",
    "print(np.linalg.norm(res_np - (a_np + b_np)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  pyopencl 常用的syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=np.random.rand(m*n).astype(np.float32)\n",
    "\n",
    "\n",
    "# create a m*n array, initialized with random float32 precision data\n",
    "import pyopencl as cl\n",
    "ctx=cl.create_some_context() #create space for the context, which context, how big size and which devices??\n",
    "queue=cl.CommandQueue(ctx)   #request a chunk of memory in GPU, so a shown above can be transferred to the GPU\n",
    "\n",
    "\n",
    "mf=cl.mem_flags\n",
    "a_dev=cl.Buffer(ctx,mf.READ_WRITE,size=a.nbytes)\n",
    "cl.enqueue_write_buffer(queue,a_dev,a)\n",
    "prg=cl.Program(\n",
    " \n",
    "# your kernel file here\n",
    " \n",
    ").build()\n",
    "\n",
    "\n",
    "# kernel file\n",
    "__kernel void kernel_func(__global float *a)\n",
    "{\n",
    "# your kernel function here\n",
    "}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
